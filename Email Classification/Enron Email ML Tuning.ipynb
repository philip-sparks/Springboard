{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries and Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import walk\n",
    "from warnings import filterwarnings\n",
    "import sys, email, csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import codecs\n",
    "import sklearn as sk\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the Kaggle-Enron emails file that has been aggregated into one CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Enron data\n",
    "emails_df = pd.read_csv('emails.csv', parse_dates=True, engine=\"python\", delimiter=\",\", encoding='utf-8', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the size and initial values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(843222, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allen-p/_sent_mail/1.</td>\n",
       "      <td>Message-ID: &lt;18782981.1075855378110.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>allen-p/_sent_mail/10.</td>\n",
       "      <td>Message-ID: &lt;15464986.1075855378456.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allen-p/_sent_mail/100.</td>\n",
       "      <td>Message-ID: &lt;24216240.1075855687451.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allen-p/_sent_mail/1000.</td>\n",
       "      <td>Message-ID: &lt;13505866.1075863688222.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>allen-p/_sent_mail/1001.</td>\n",
       "      <td>Message-ID: &lt;30922949.1075863688243.JavaMail.e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       file                                            message\n",
       "0     allen-p/_sent_mail/1.  Message-ID: <18782981.1075855378110.JavaMail.e...\n",
       "1    allen-p/_sent_mail/10.  Message-ID: <15464986.1075855378456.JavaMail.e...\n",
       "2   allen-p/_sent_mail/100.  Message-ID: <24216240.1075855687451.JavaMail.e...\n",
       "3  allen-p/_sent_mail/1000.  Message-ID: <13505866.1075863688222.JavaMail.e...\n",
       "4  allen-p/_sent_mail/1001.  Message-ID: <30922949.1075863688243.JavaMail.e..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace NA values from initial set\n",
    "emails_df_NA = emails_df.replace(to_replace='None', value=np.nan).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(554134, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails_df_NA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allen-p/_sent_mail/1.</td>\n",
       "      <td>Message-ID: &lt;18782981.1075855378110.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>allen-p/_sent_mail/10.</td>\n",
       "      <td>Message-ID: &lt;15464986.1075855378456.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allen-p/_sent_mail/100.</td>\n",
       "      <td>Message-ID: &lt;24216240.1075855687451.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allen-p/_sent_mail/1000.</td>\n",
       "      <td>Message-ID: &lt;13505866.1075863688222.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>allen-p/_sent_mail/1001.</td>\n",
       "      <td>Message-ID: &lt;30922949.1075863688243.JavaMail.e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       file                                            message\n",
       "0     allen-p/_sent_mail/1.  Message-ID: <18782981.1075855378110.JavaMail.e...\n",
       "1    allen-p/_sent_mail/10.  Message-ID: <15464986.1075855378456.JavaMail.e...\n",
       "2   allen-p/_sent_mail/100.  Message-ID: <24216240.1075855687451.JavaMail.e...\n",
       "3  allen-p/_sent_mail/1000.  Message-ID: <13505866.1075863688222.JavaMail.e...\n",
       "4  allen-p/_sent_mail/1001.  Message-ID: <30922949.1075863688243.JavaMail.e..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails_df_NA.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### These data cleaning steps for the Kaggle-Enron file extract the text from the message header and create additional features (to, from, content, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Helper function 1\n",
    "def get_text_from_email(msg):\n",
    "    '''To get the content from email objects'''\n",
    "    parts = []\n",
    "    for part in msg.walk():\n",
    "        if part.get_content_type() == 'text/plain':\n",
    "            parts.append( part.get_payload() )\n",
    "    return ''.join(parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Helper function 2\n",
    "def split_email_addresses(line):\n",
    "    '''To separate multiple email addresses'''\n",
    "    if line:\n",
    "        addrs = line.split(',')\n",
    "        addrs = frozenset(map(lambda x: x.strip(), addrs))\n",
    "    else:\n",
    "        addrs = None\n",
    "    return addrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Map Enron email data to be added into pandas dataframe\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf8')\n",
    "\n",
    "# Parse the emails into a list email objects\n",
    "messages = list(map(email.message_from_string, emails_df_NA['message']))\n",
    "emails_df_NA.drop('message', axis=1, inplace=True)\n",
    "\n",
    "# Get fields from parsed email objects\n",
    "keys = messages[0].keys()\n",
    "for key in keys:\n",
    "    emails_df_NA[key] = [doc[key] for doc in messages]\n",
    "\n",
    "# Parse content from emails\n",
    "emails_df_NA['content'] = list(map(get_text_from_email, messages))\n",
    "\n",
    "# Split multiple email addresses\n",
    "emails_df_NA['From'] = emails_df_NA['From'].map(split_email_addresses)\n",
    "emails_df_NA['To'] = emails_df_NA['To'].map(split_email_addresses)\n",
    "\n",
    "# Extract the root of 'file' as 'user'\n",
    "emails_df_NA['user'] = emails_df_NA['file'].map(lambda x:x.split('/')[0])\n",
    "del messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>Message-ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Mime-Version</th>\n",
       "      <th>Content-Type</th>\n",
       "      <th>Content-Transfer-Encoding</th>\n",
       "      <th>X-From</th>\n",
       "      <th>X-To</th>\n",
       "      <th>X-cc</th>\n",
       "      <th>X-bcc</th>\n",
       "      <th>X-Folder</th>\n",
       "      <th>X-Origin</th>\n",
       "      <th>X-FileName</th>\n",
       "      <th>content</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allen-p/_sent_mail/1.</td>\n",
       "      <td>&lt;18782981.1075855378110.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Mon, 14 May 2001 16:39:00 -0700 (PDT)</td>\n",
       "      <td>(phillip.allen@enron.com)</td>\n",
       "      <td>(tim.belden@enron.com)</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>7bit</td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>Tim Belden &lt;Tim Belden/Enron@EnronXGate&gt;</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Se...</td>\n",
       "      <td>Allen-P</td>\n",
       "      <td>pallen (Non-Privileged).pst</td>\n",
       "      <td>Here is our forecast\\n\\n</td>\n",
       "      <td>allen-p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>allen-p/_sent_mail/10.</td>\n",
       "      <td>&lt;15464986.1075855378456.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Fri, 4 May 2001 13:51:00 -0700 (PDT)</td>\n",
       "      <td>(phillip.allen@enron.com)</td>\n",
       "      <td>(john.lavorato@enron.com)</td>\n",
       "      <td>Re:</td>\n",
       "      <td>1.0</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>7bit</td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>John J Lavorato &lt;John J Lavorato/ENRON@enronXg...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Se...</td>\n",
       "      <td>Allen-P</td>\n",
       "      <td>pallen (Non-Privileged).pst</td>\n",
       "      <td>Traveling to have a business meeting takes the...</td>\n",
       "      <td>allen-p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allen-p/_sent_mail/100.</td>\n",
       "      <td>&lt;24216240.1075855687451.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Wed, 18 Oct 2000 03:00:00 -0700 (PDT)</td>\n",
       "      <td>(phillip.allen@enron.com)</td>\n",
       "      <td>(leah.arsdall@enron.com)</td>\n",
       "      <td>Re: test</td>\n",
       "      <td>1.0</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>7bit</td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>Leah Van Arsdall</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\Phillip_Allen_Dec2000\\Notes Folders\\'sent mail</td>\n",
       "      <td>Allen-P</td>\n",
       "      <td>pallen.nsf</td>\n",
       "      <td>test successful.  way to go!!!</td>\n",
       "      <td>allen-p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allen-p/_sent_mail/1000.</td>\n",
       "      <td>&lt;13505866.1075863688222.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Mon, 23 Oct 2000 06:13:00 -0700 (PDT)</td>\n",
       "      <td>(phillip.allen@enron.com)</td>\n",
       "      <td>(randall.gay@enron.com)</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>7bit</td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>Randall L Gay</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\Phillip_Allen_Dec2000\\Notes Folders\\'sent mail</td>\n",
       "      <td>Allen-P</td>\n",
       "      <td>pallen.nsf</td>\n",
       "      <td>Randy,\\n\\n Can you send me a schedule of the s...</td>\n",
       "      <td>allen-p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>allen-p/_sent_mail/1001.</td>\n",
       "      <td>&lt;30922949.1075863688243.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Thu, 31 Aug 2000 05:07:00 -0700 (PDT)</td>\n",
       "      <td>(phillip.allen@enron.com)</td>\n",
       "      <td>(greg.piper@enron.com)</td>\n",
       "      <td>Re: Hello</td>\n",
       "      <td>1.0</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>7bit</td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>Greg Piper</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\Phillip_Allen_Dec2000\\Notes Folders\\'sent mail</td>\n",
       "      <td>Allen-P</td>\n",
       "      <td>pallen.nsf</td>\n",
       "      <td>Let's shoot for Tuesday at 11:45.</td>\n",
       "      <td>allen-p</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       file                                     Message-ID  \\\n",
       "0     allen-p/_sent_mail/1.  <18782981.1075855378110.JavaMail.evans@thyme>   \n",
       "1    allen-p/_sent_mail/10.  <15464986.1075855378456.JavaMail.evans@thyme>   \n",
       "2   allen-p/_sent_mail/100.  <24216240.1075855687451.JavaMail.evans@thyme>   \n",
       "3  allen-p/_sent_mail/1000.  <13505866.1075863688222.JavaMail.evans@thyme>   \n",
       "4  allen-p/_sent_mail/1001.  <30922949.1075863688243.JavaMail.evans@thyme>   \n",
       "\n",
       "                                    Date                       From  \\\n",
       "0  Mon, 14 May 2001 16:39:00 -0700 (PDT)  (phillip.allen@enron.com)   \n",
       "1   Fri, 4 May 2001 13:51:00 -0700 (PDT)  (phillip.allen@enron.com)   \n",
       "2  Wed, 18 Oct 2000 03:00:00 -0700 (PDT)  (phillip.allen@enron.com)   \n",
       "3  Mon, 23 Oct 2000 06:13:00 -0700 (PDT)  (phillip.allen@enron.com)   \n",
       "4  Thu, 31 Aug 2000 05:07:00 -0700 (PDT)  (phillip.allen@enron.com)   \n",
       "\n",
       "                          To    Subject Mime-Version  \\\n",
       "0     (tim.belden@enron.com)                     1.0   \n",
       "1  (john.lavorato@enron.com)        Re:          1.0   \n",
       "2   (leah.arsdall@enron.com)   Re: test          1.0   \n",
       "3    (randall.gay@enron.com)                     1.0   \n",
       "4     (greg.piper@enron.com)  Re: Hello          1.0   \n",
       "\n",
       "                   Content-Type Content-Transfer-Encoding           X-From  \\\n",
       "0  text/plain; charset=us-ascii                      7bit  Phillip K Allen   \n",
       "1  text/plain; charset=us-ascii                      7bit  Phillip K Allen   \n",
       "2  text/plain; charset=us-ascii                      7bit  Phillip K Allen   \n",
       "3  text/plain; charset=us-ascii                      7bit  Phillip K Allen   \n",
       "4  text/plain; charset=us-ascii                      7bit  Phillip K Allen   \n",
       "\n",
       "                                                X-To X-cc X-bcc  \\\n",
       "0           Tim Belden <Tim Belden/Enron@EnronXGate>              \n",
       "1  John J Lavorato <John J Lavorato/ENRON@enronXg...              \n",
       "2                                   Leah Van Arsdall              \n",
       "3                                      Randall L Gay              \n",
       "4                                         Greg Piper              \n",
       "\n",
       "                                            X-Folder X-Origin  \\\n",
       "0  \\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Se...  Allen-P   \n",
       "1  \\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Se...  Allen-P   \n",
       "2    \\Phillip_Allen_Dec2000\\Notes Folders\\'sent mail  Allen-P   \n",
       "3    \\Phillip_Allen_Dec2000\\Notes Folders\\'sent mail  Allen-P   \n",
       "4    \\Phillip_Allen_Dec2000\\Notes Folders\\'sent mail  Allen-P   \n",
       "\n",
       "                    X-FileName  \\\n",
       "0  pallen (Non-Privileged).pst   \n",
       "1  pallen (Non-Privileged).pst   \n",
       "2                   pallen.nsf   \n",
       "3                   pallen.nsf   \n",
       "4                   pallen.nsf   \n",
       "\n",
       "                                             content     user  \n",
       "0                          Here is our forecast\\n\\n   allen-p  \n",
       "1  Traveling to have a business meeting takes the...  allen-p  \n",
       "2                     test successful.  way to go!!!  allen-p  \n",
       "3  Randy,\\n\\n Can you send me a schedule of the s...  allen-p  \n",
       "4                Let's shoot for Tuesday at 11:45.    allen-p  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails_df_NA.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This data cleaning is for the email tags. These tags are then joined to the Kaggle-Enron set based the uniquely identifible \"date\" field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Gather training tags\n",
    "csvFileArray = []\n",
    "outlst = []\n",
    "\n",
    "for directory in walk(\".\"):\n",
    "    for fle in directory[2]:\n",
    "        if \"personal\" in directory[0] and \".csv\" in fle:\n",
    "            csvFileArray = []\n",
    "            path = directory[0] + \"/\" + fle\n",
    "            csvfile = codecs.open(path, 'rb')\n",
    "            for row in csv.reader(csvfile, delimiter = '.'):\n",
    "                csvFileArray.append(row)\n",
    "            dte = str(csvFileArray[0])\n",
    "            dte = dte[8:-2]\n",
    "            outlst.append((\"personal\", fle, dte))\n",
    "        \n",
    "        elif \"business\" in directory[0] and \".csv\" in fle:\n",
    "            csvFileArray = []\n",
    "            path = directory[0] + \"/\" + fle\n",
    "            csvfile = codecs.open(path, 'rb')\n",
    "            for row in csv.reader(csvfile, delimiter = '.'):\n",
    "                csvFileArray.append(row)\n",
    "            dte = str(csvFileArray[0])\n",
    "            dte = dte[8:-2]\n",
    "            outlst.append((\"business\", fle, dte))\n",
    "            \n",
    "        elif \"chain_mails\" in directory[0] and \".csv\" in fle:\n",
    "            csvFileArray = []\n",
    "            path = directory[0] + \"/\" + fle\n",
    "            csvfile = codecs.open(path, 'rb')\n",
    "            for row in csv.reader(csvfile, delimiter = \".\"):\n",
    "                csvFileArray.append(row)\n",
    "            dte = str(csvFileArray[0])\n",
    "            dte = dte[8:-2]\n",
    "            outlst.append((\"chain_mails\", fle, dte))\n",
    "            \n",
    "        elif \"enron_online\" in directory[0] and \".csv\" in fle:\n",
    "            csvFileArray = []\n",
    "            path = directory[0] + \"/\" + fle\n",
    "            csvfile = codecs.open(path, 'rb')\n",
    "            for row in csv.reader(csvfile, delimiter = \".\"):\n",
    "                csvFileArray.append(row)\n",
    "            dte = str(csvFileArray[0])\n",
    "            dte = dte[8:-2]\n",
    "            outlst.append((\"enron_online\", fle, dte))\n",
    "            \n",
    "        elif \"general_announcements\" in directory[0] and \".csv\" in fle:\n",
    "            csvFileArray = []\n",
    "            path = directory[0] + \"/\" + fle\n",
    "            csvfile = codecs.open(path, 'rb')\n",
    "            for row in csv.reader(csvfile, delimiter = \".\"):\n",
    "                csvFileArray.append(row)\n",
    "            dte = str(csvFileArray[0])\n",
    "            dte = dte[8:-2]\n",
    "            outlst.append((\"general_announcements\", fle, dte))\n",
    "            \n",
    "        elif \"human_resources\" in directory[0] and \".csv\" in fle:\n",
    "            csvFileArray = []\n",
    "            path = directory[0] + \"/\" + fle\n",
    "            csvfile = codecs.open(path, 'rb')\n",
    "            for row in csv.reader(csvfile, delimiter = \".\"):\n",
    "                csvFileArray.append(row)\n",
    "            dte = str(csvFileArray[0])\n",
    "            dte = dte[8:-2]\n",
    "            outlst.append((\"human_resources\", fle, dte))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load training tags into pandas dataframe\n",
    "tags = pd.DataFrame(list(outlst), columns=['tags','file','date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Join the two datasets\n",
    "emails_merged_full = pd.merge(emails_df_NA, tags, left_on = 'Date', right_on = 'date', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12607, 21)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of training samples\n",
    "emails_merged_full.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here is our full dataset ready to be used for machine learning modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_x</th>\n",
       "      <th>Message-ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Mime-Version</th>\n",
       "      <th>Content-Type</th>\n",
       "      <th>Content-Transfer-Encoding</th>\n",
       "      <th>X-From</th>\n",
       "      <th>...</th>\n",
       "      <th>X-cc</th>\n",
       "      <th>X-bcc</th>\n",
       "      <th>X-Folder</th>\n",
       "      <th>X-Origin</th>\n",
       "      <th>X-FileName</th>\n",
       "      <th>content</th>\n",
       "      <th>user</th>\n",
       "      <th>tags</th>\n",
       "      <th>file_y</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allen-p/_sent_mail/26.</td>\n",
       "      <td>&lt;15164543.1075855378954.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Wed, 25 Apr 2001 16:52:00 -0700 (PDT)</td>\n",
       "      <td>(phillip.allen@enron.com)</td>\n",
       "      <td>(john.lavorato@enron.com)</td>\n",
       "      <td>Re: This morning's Commission meeting delayed</td>\n",
       "      <td>1.0</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>7bit</td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Se...</td>\n",
       "      <td>Allen-P</td>\n",
       "      <td>pallen (Non-Privileged).pst</td>\n",
       "      <td>\\n---------------------- Forwarded by Phillip ...</td>\n",
       "      <td>allen-p</td>\n",
       "      <td>enron_online</td>\n",
       "      <td>Ron.williams-w3.timbelden.2.csv</td>\n",
       "      <td>Wed, 25 Apr 2001 16:52:00 -0700 (PDT)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>allen-p/sent_items/61.</td>\n",
       "      <td>&lt;24466219.1075858638656.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Wed, 25 Apr 2001 16:52:00 -0700 (PDT)</td>\n",
       "      <td>(phillip.allen@enron.com)</td>\n",
       "      <td>(john.lavorato@enron.com)</td>\n",
       "      <td>Re: This morning's Commission meeting delayed</td>\n",
       "      <td>1.0</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>7bit</td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\PALLEN (Non-Privileged)\\Allen, Phillip K.\\Sen...</td>\n",
       "      <td>Allen-P</td>\n",
       "      <td>PALLEN (Non-Privileged).pst</td>\n",
       "      <td>\\n---------------------- Forwarded by Phillip ...</td>\n",
       "      <td>allen-p</td>\n",
       "      <td>enron_online</td>\n",
       "      <td>Ron.williams-w3.timbelden.2.csv</td>\n",
       "      <td>Wed, 25 Apr 2001 16:52:00 -0700 (PDT)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>williams-w3/timbelden/2.</td>\n",
       "      <td>&lt;12767107.1075840010399.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Wed, 25 Apr 2001 16:52:00 -0700 (PDT)</td>\n",
       "      <td>(tim.belden@enron.com)</td>\n",
       "      <td>(robert.badeer@enron.com, bill.iii@enron.com, ...</td>\n",
       "      <td>Daily EOL/ICE Summary 4/24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>7bit</td>\n",
       "      <td>Tim Belden &lt;Tim Belden/HOU/ECT@ECT&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\ExMerge - Williams III, Bill\\TimBelden</td>\n",
       "      <td>WILLIAMS-W3</td>\n",
       "      <td></td>\n",
       "      <td>The last couple of days on eol have been amazi...</td>\n",
       "      <td>williams-w3</td>\n",
       "      <td>enron_online</td>\n",
       "      <td>Ron.williams-w3.timbelden.2.csv</td>\n",
       "      <td>Wed, 25 Apr 2001 16:52:00 -0700 (PDT)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allen-p/_sent_mail/440.</td>\n",
       "      <td>&lt;29628244.1075855725718.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Mon, 19 Mar 2001 00:45:00 -0800 (PST)</td>\n",
       "      <td>(phillip.allen@enron.com)</td>\n",
       "      <td>(llewter@austin.rr.com)</td>\n",
       "      <td>Re: Buyout</td>\n",
       "      <td>1.0</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>7bit</td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\Phillip_Allen_June2001\\Notes Folders\\'sent mail</td>\n",
       "      <td>Allen-P</td>\n",
       "      <td>pallen.nsf</td>\n",
       "      <td>Larrry,\\n\\nI realize you are disappointed abou...</td>\n",
       "      <td>allen-p</td>\n",
       "      <td>business</td>\n",
       "      <td>Ron.beck-s.apollo__beth.9.csv</td>\n",
       "      <td>Mon, 19 Mar 2001 00:45:00 -0800 (PST)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>allen-p/all_documents/459.</td>\n",
       "      <td>&lt;18425275.1075855696118.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>Mon, 19 Mar 2001 00:45:00 -0800 (PST)</td>\n",
       "      <td>(phillip.allen@enron.com)</td>\n",
       "      <td>(llewter@austin.rr.com)</td>\n",
       "      <td>Re: Buyout</td>\n",
       "      <td>1.0</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>7bit</td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\Phillip_Allen_June2001\\Notes Folders\\All docu...</td>\n",
       "      <td>Allen-P</td>\n",
       "      <td>pallen.nsf</td>\n",
       "      <td>Larrry,\\n\\nI realize you are disappointed abou...</td>\n",
       "      <td>allen-p</td>\n",
       "      <td>business</td>\n",
       "      <td>Ron.beck-s.apollo__beth.9.csv</td>\n",
       "      <td>Mon, 19 Mar 2001 00:45:00 -0800 (PST)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       file_x                                     Message-ID  \\\n",
       "0      allen-p/_sent_mail/26.  <15164543.1075855378954.JavaMail.evans@thyme>   \n",
       "1      allen-p/sent_items/61.  <24466219.1075858638656.JavaMail.evans@thyme>   \n",
       "2    williams-w3/timbelden/2.  <12767107.1075840010399.JavaMail.evans@thyme>   \n",
       "3     allen-p/_sent_mail/440.  <29628244.1075855725718.JavaMail.evans@thyme>   \n",
       "4  allen-p/all_documents/459.  <18425275.1075855696118.JavaMail.evans@thyme>   \n",
       "\n",
       "                                    Date                       From  \\\n",
       "0  Wed, 25 Apr 2001 16:52:00 -0700 (PDT)  (phillip.allen@enron.com)   \n",
       "1  Wed, 25 Apr 2001 16:52:00 -0700 (PDT)  (phillip.allen@enron.com)   \n",
       "2  Wed, 25 Apr 2001 16:52:00 -0700 (PDT)     (tim.belden@enron.com)   \n",
       "3  Mon, 19 Mar 2001 00:45:00 -0800 (PST)  (phillip.allen@enron.com)   \n",
       "4  Mon, 19 Mar 2001 00:45:00 -0800 (PST)  (phillip.allen@enron.com)   \n",
       "\n",
       "                                                  To  \\\n",
       "0                          (john.lavorato@enron.com)   \n",
       "1                          (john.lavorato@enron.com)   \n",
       "2  (robert.badeer@enron.com, bill.iii@enron.com, ...   \n",
       "3                            (llewter@austin.rr.com)   \n",
       "4                            (llewter@austin.rr.com)   \n",
       "\n",
       "                                         Subject Mime-Version  \\\n",
       "0  Re: This morning's Commission meeting delayed          1.0   \n",
       "1  Re: This morning's Commission meeting delayed          1.0   \n",
       "2                     Daily EOL/ICE Summary 4/24          1.0   \n",
       "3                                     Re: Buyout          1.0   \n",
       "4                                     Re: Buyout          1.0   \n",
       "\n",
       "                   Content-Type Content-Transfer-Encoding  \\\n",
       "0  text/plain; charset=us-ascii                      7bit   \n",
       "1  text/plain; charset=us-ascii                      7bit   \n",
       "2  text/plain; charset=us-ascii                      7bit   \n",
       "3  text/plain; charset=us-ascii                      7bit   \n",
       "4  text/plain; charset=us-ascii                      7bit   \n",
       "\n",
       "                                X-From                  ...                    \\\n",
       "0                      Phillip K Allen                  ...                     \n",
       "1                      Phillip K Allen                  ...                     \n",
       "2  Tim Belden <Tim Belden/HOU/ECT@ECT>                  ...                     \n",
       "3                      Phillip K Allen                  ...                     \n",
       "4                      Phillip K Allen                  ...                     \n",
       "\n",
       "  X-cc X-bcc                                           X-Folder     X-Origin  \\\n",
       "0             \\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Se...      Allen-P   \n",
       "1             \\PALLEN (Non-Privileged)\\Allen, Phillip K.\\Sen...      Allen-P   \n",
       "2                       \\ExMerge - Williams III, Bill\\TimBelden  WILLIAMS-W3   \n",
       "3              \\Phillip_Allen_June2001\\Notes Folders\\'sent mail      Allen-P   \n",
       "4             \\Phillip_Allen_June2001\\Notes Folders\\All docu...      Allen-P   \n",
       "\n",
       "                    X-FileName  \\\n",
       "0  pallen (Non-Privileged).pst   \n",
       "1  PALLEN (Non-Privileged).pst   \n",
       "2                                \n",
       "3                   pallen.nsf   \n",
       "4                   pallen.nsf   \n",
       "\n",
       "                                             content         user  \\\n",
       "0  \\n---------------------- Forwarded by Phillip ...      allen-p   \n",
       "1  \\n---------------------- Forwarded by Phillip ...      allen-p   \n",
       "2  The last couple of days on eol have been amazi...  williams-w3   \n",
       "3  Larrry,\\n\\nI realize you are disappointed abou...      allen-p   \n",
       "4  Larrry,\\n\\nI realize you are disappointed abou...      allen-p   \n",
       "\n",
       "           tags                           file_y  \\\n",
       "0  enron_online  Ron.williams-w3.timbelden.2.csv   \n",
       "1  enron_online  Ron.williams-w3.timbelden.2.csv   \n",
       "2  enron_online  Ron.williams-w3.timbelden.2.csv   \n",
       "3      business    Ron.beck-s.apollo__beth.9.csv   \n",
       "4      business    Ron.beck-s.apollo__beth.9.csv   \n",
       "\n",
       "                                    date  \n",
       "0  Wed, 25 Apr 2001 16:52:00 -0700 (PDT)  \n",
       "1  Wed, 25 Apr 2001 16:52:00 -0700 (PDT)  \n",
       "2  Wed, 25 Apr 2001 16:52:00 -0700 (PDT)  \n",
       "3  Mon, 19 Mar 2001 00:45:00 -0800 (PST)  \n",
       "4  Mon, 19 Mar 2001 00:45:00 -0800 (PST)  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Curated dataset ready for scikit-learn tuning\n",
    "emails_merged_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since it would be nice to only do the data cleaning process once, pickle allows you to save the data frame for recollection each time one loads the jupyter notebook from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pickle process to save data in case you don't want to rerun the jupyter notebook\n",
    "pickle.dump( emails_merged_full, open( \"save.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pickle process to load data\n",
    "emails_merged_full = pickle.load( open( \"save.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_vals = ['business', 'general_annoucements', 'enron_online',\n",
    "               'personal', 'chain_emails', 'human_resources']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This count vectorizer step takes our content within the emails and converts the content into a sparse matrix where the values are given by how frequent a word appears."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# From http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n",
    "# Count Vectorize the data\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(emails_merged_full['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12607, 38051)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14233"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect.vocabulary_.get(u'enron')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF (Term Frequency - Inverse Document Frequency) is used to weight the frequency of the words counted against the overall number of times a word appears in all documents. This allows the modeler to remove common words (the, it, or, and, etc.) from being preceived as important values to the classifiers below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12607, 38051)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tf-idf the content\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "X_train_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12607, 38051)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### In order to validate our models later, split the data into a test and training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "enron_train, enron_test = train_test_split(emails_merged_full, test_size=0.2)\n",
    "\n",
    "emails_test = enron_test.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2522, 21)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enron_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2522, 36747)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new_counts_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10085, 21)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enron_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2522,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling/Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our first model, Multinomial Naive Bayes, produces a probability for each email in each classification and tags the email with the highest value to that class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74900872323552736"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict Values\n",
    "\n",
    "# This \"pipeline\" actually works.\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Taking the training data and turning it into a count feature vector\n",
    "count_vect_2 = CountVectorizer()\n",
    "X_train_counts_2 = count_vect_2.fit_transform(enron_train.content)\n",
    "\n",
    "# Turning the vector into a weighted feature vector\n",
    "tfidf_transformer_2 = TfidfTransformer()\n",
    "X_train_tfidf_2 = tfidf_transformer_2.fit_transform(X_train_counts_2)\n",
    "\n",
    "# Using a specific algo to train the model\n",
    "clf_2 = MultinomialNB().fit(X_train_tfidf_2, enron_train.tags)\n",
    "\n",
    "# Prepare the test data into a count vector\n",
    "X_new_counts_2 = count_vect_2.transform(enron_test.content)\n",
    "# Turning the vector into a weighted feature vector for the test data\n",
    "X_new_tfidf_2 = tfidf_transformer_2.transform(X_new_counts_2)\n",
    "\n",
    "# Making a prediction for the test data\n",
    "predicted_2 = clf_2.predict(X_new_tfidf_2)\n",
    "\n",
    "# Measure the accuracy\n",
    "np.mean(predicted_2 == enron_test.tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our second model, a SVC, separates the training data into different hyperplanes until each classification is clearly defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94448850118953209"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LinearSupportVectorClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "count_vect_3 = CountVectorizer()\n",
    "X_train_counts_3 = count_vect_3.fit_transform(enron_train.content)\n",
    "\n",
    "tfidf_transformer_3 = TfidfTransformer()\n",
    "X_train_tfidf_3 = tfidf_transformer_3.fit_transform(X_train_counts_3)\n",
    "\n",
    "clf_3 = LinearSVC().fit(X_train_tfidf_3, enron_train.tags)\n",
    "\n",
    "X_new_counts_3 = count_vect_3.transform(enron_test.content)\n",
    "X_new_tfidf_3 = tfidf_transformer_3.transform(X_new_counts_3)\n",
    "\n",
    "predicted_3 = clf_3.predict(X_new_tfidf_3)\n",
    "\n",
    "np.mean(predicted_3 == enron_test.tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our third model, stocastic gradient descent, fits a line to the data by continuously updating the importance of each word in the data set to the fitted line. This updating these weights after enough iterations produces trend lines that allow for the model to accurately place new data points and correctly classify the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93021411578112612"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#StocasticGradientDescentClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "count_vect_4 = CountVectorizer()\n",
    "X_train_counts_4 = count_vect_4.fit_transform(enron_train.content)\n",
    "\n",
    "tfidf_transformer_4 = TfidfTransformer()\n",
    "X_train_tfidf_4 = tfidf_transformer_4.fit_transform(X_train_counts_4)\n",
    "\n",
    "clf_4 = SGDClassifier().fit(X_train_tfidf_4, enron_train.tags)\n",
    "\n",
    "X_new_counts_4 = count_vect_4.transform(enron_test.content)\n",
    "X_new_tfidf_4 = tfidf_transformer_4.transform(X_new_counts_4)\n",
    "\n",
    "predicted_4 = clf_4.predict(X_new_tfidf_4)\n",
    "\n",
    "np.mean(predicted_4 == enron_test.tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reporting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For each classification model, a report and confusion matrix was printed to show the precision and accuracy of each model (F1-score), as well as which classifications the models were correctly (or incorrectly) assigning emails to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Multinomial Naive Bayes\n",
    "import sys\n",
    "stdout = sys.stdout\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf-8')\n",
    "sys.stdout = stdout\n",
    "\n",
    "from sklearn import metrics\n",
    "report_2 = metrics.classification_report(enron_test.tags, predicted_2)\n",
    "print(report_2)\n",
    "# , target_names = target_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[698,   0,   0,  90,   0,   7],\n",
       "       [  2,   0,   0,   0,   0,   4],\n",
       "       [ 35,   0,   9,  12,   0,   0],\n",
       "       [ 52,   0,   0, 815,   0,   1],\n",
       "       [156,   0,   0,  70,  18,   2],\n",
       "       [161,   0,   0,  41,   0, 349]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(enron_test.tags, predicted_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SVC\n",
    "report_3 =  metrics.classification_report(enron_test.tags, predicted_3)\n",
    "print(report_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[752,   0,   1,  11,   8,  23],\n",
       "       [  1,   5,   0,   0,   0,   0],\n",
       "       [  6,   0,  44,   6,   0,   0],\n",
       "       [ 22,   0,   0, 840,   1,   5],\n",
       "       [ 16,   0,   0,   4, 222,   4],\n",
       "       [ 23,   0,   0,   6,   3, 519]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(enron_test.tags, predicted_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SGD\n",
    "report_4 =  metrics.classification_report(enron_test.tags, predicted_4)\n",
    "print(report_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[764,   0,   1,  24,   8,  17],\n",
       "       [  0,   5,   0,   0,   0,   1],\n",
       "       [ 10,   0,  48,   0,   0,   1],\n",
       "       [ 25,   0,   9, 865,   5,   1],\n",
       "       [ 36,   0,   0,   4, 186,   8],\n",
       "       [ 35,   0,   0,   6,   4, 459]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(enron_test.tags, predicted_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sorting the indices shows that there's no overlapping data in both the \n",
    "# training and test sets. This confirms that from sklearn.model_selection import train_test_split\n",
    "# worked and validates our training runnings.\n",
    "enron_train.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enron_test.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -7.83492143,  -7.94785047, -11.02964212, ..., -11.02964212,\n",
       "        -10.94883206, -11.02964212],\n",
       "       [-10.48615122, -10.52820499, -10.52820499, ..., -10.52820499,\n",
       "        -10.52820499, -10.52820499],\n",
       "       [ -9.51673258,  -9.70873553, -10.56976036, ..., -10.56976036,\n",
       "        -10.56976036, -10.56976036],\n",
       "       [ -7.93176251,  -9.11840093, -10.93987481, ..., -11.12588365,\n",
       "        -11.12588365, -11.12588365],\n",
       "       [ -7.79185651,  -8.80525667, -10.71273363, ..., -10.71273363,\n",
       "        -10.71273363, -10.71273363],\n",
       "       [ -7.94593507,  -9.34947906, -10.67568843, ..., -10.68552128,\n",
       "        -10.87273204, -10.86306173]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will match the word index back to the particular class\n",
    "clf_2.feature_log_prob_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect_2.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{u'sowell': 31537,\n",
    " u'chudson': 9256,\n",
    " u'woods': 36299,\n",
    " u'paolis': 25426,\n",
    " u'hanging': 16949,\n",
    " u'woody': 36308,\n",
    " u'lenci': 20987,\n",
    " u'5989': 3100,\n",
    " u'hermans': 17358,\n",
    " u'caney': 8432,\n",
    " u'5981': 3098,\n",
    " u'5984': 3099,\n",
    " ...\n",
    "  u'diebold': 12102,\n",
    " u'918': 4072,\n",
    " u'refundable': 28330,\n",
    " u'914': 4064,\n",
    " u'917': 4071,\n",
    " u'916': 4067,\n",
    " u'910': 4060,\n",
    " u'restoring': 28836,\n",
    " u'rhaynes': 29031,\n",
    " u'eickenroht': 13389,\n",
    " u'retains': 28885,\n",
    " u'rashpal': 27881,\n",
    " u'mt_block_size': 23526,\n",
    " u'disparaging': 12312,\n",
    " ...}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Naive Bayes Reporting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Although Naive Bayes did not produce the most accurate or precise model compared to the SVC or SGD ones, it does allow for the engineer to see which words were assigned the highest log probability values. These values help determine which classification to give the email, so they can be interesting to review and give insight into the dataset. \n",
    "\n",
    "#### Note: You must run this for each category in order to see the log probability values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Iterate and sort values\n",
    "tple_lst_business = []\n",
    "for key, val in vocab.iteritems():\n",
    "    #num = val\n",
    "    log_prob = feature_log_prob_[0, val]\n",
    "    tple = (key, log_prob)\n",
    "    tple_lst_business.append(tple)\n",
    "tple_lst_business.sort(key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sorted word output.\n",
    "tple_lst_business"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[(u'the', -5.2344390447471332),\n",
    " (u'to', -5.5326198225148131),\n",
    " (u'and', -5.9118128902144278),\n",
    " (u'ect', -5.9885707257438465),\n",
    " (u'of', -6.0590707933703145),\n",
    " (u'enron', -6.1221837255157627),\n",
    " (u'you', -6.1926160393274081),\n",
    " (u'in', -6.2502001944603141),\n",
    " (u'for', -6.3572072269973452),\n",
    " (u'is', -6.4207707714190683),\n",
    " (u'on', -6.4789012429524124),\n",
    " (u'that', -6.5070746354992046),\n",
    " (u'we', -6.5413514223621947),\n",
    " (u'com', -6.5448994667459468),\n",
    " (u'this', -6.5619840519833668),\n",
    " (u'hou', -6.6197132934115857),\n",
    " (u'have', -6.6640093676177647),\n",
    " (u'please', -6.6659553649840637),\n",
    " ...\n",
    " (u'bring', -9.2643486958075059),\n",
    " (u'brief', -9.2648773248202403),\n",
    " (u'darrell', -9.2649839747922123),\n",
    " (u'likely', -9.2653262298710999),\n",
    " (u'chance', -9.2658171841737236),\n",
    " (u'notified', -9.2675006184168414),\n",
    " (u'sheri', -9.2676337079923954),\n",
    " (u'register', -9.268031050365229),\n",
    " (u'average', -9.2692087425854055),\n",
    " (u'modem', -9.2739486764453734),\n",
    " (u'determine', -9.2758203079057679),\n",
    " (u'far', -9.2760597911275617),\n",
    " (u'haven', -9.2767078273487833),\n",
    " (u'buy', -9.2768293312924683),\n",
    " ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Iterate and sort values\n",
    "tple_lst_cm = []\n",
    "for key, val in vocab.iteritems():\n",
    "    log_prob = feature_log_prob_[1, val]\n",
    "    tple = (key, log_prob)\n",
    "    tple_lst_cm.append(tple)\n",
    "tple_lst_cm.sort(key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tple_lst_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(u'the', -9.2715167371058023),\n",
    " (u'you', -9.4911095288583631),\n",
    " (u'to', -9.5894030139134969),\n",
    " (u'your', -9.6740329583020266),\n",
    " (u'and', -9.7002726600961644),\n",
    " (u'com', -9.7100551505311508),\n",
    " (u'of', -9.7539218706547111),\n",
    " (u'mail', -9.7561803858792775),\n",
    " ...\n",
    "  (u'dm', -10.465234365336563),\n",
    " (u'powder', -10.465234365336563),\n",
    " (u'bless', -10.465456359313036),\n",
    " (u'called', -10.465530517475191),\n",
    " (u'september', -10.465540483313255),\n",
    " (u'including', -10.465669448246267),\n",
    " (u'while', -10.465853741458739),\n",
    " (u'fool', -10.466141358036809),\n",
    " (u'toothpaste', -10.466358806490888),\n",
    " (u'bros', -10.466358806490888),\n",
    " (u'bacon', -10.466358806490888),\n",
    " (u'cry', -10.466358806490888),\n",
    " (u'sleepless', -10.466358806490888),\n",
    " (u'however', -10.466418384685312),\n",
    " (u'add', -10.46642765436656),\n",
    " (u'ladd', -10.466610048790363),\n",
    " (u'dwilliams', -10.466610048790363),\n",
    " (u'jbond', -10.466610048790363),\n",
    " (u'athletics', -10.466610048790363),\n",
    " (u'sonny', -10.466610048790363),\n",
    " (u'ivers', -10.466610048790363),\n",
    " (u'cdm', -10.466610048790363),\n",
    " (u'icsi', -10.466610048790363),\n",
    " (u'major', -10.46679701168947),\n",
    " (u'attacks', -10.466854507558335),\n",
    " (u'type', -10.466906794249482),\n",
    " (u'afternoon', -10.466917773423591),\n",
    " (u'branch', -10.467172751908313),\n",
    " (u'move', -10.4677013239745),\n",
    " ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Iterate and sort values\n",
    "tple_lst_imo = []\n",
    "for key, val in vocab.iteritems():\n",
    "    log_prob = feature_log_prob_[2, val]\n",
    "    tple = (key, log_prob)\n",
    "    tple_lst_imo.append(tple)\n",
    "tple_lst_imo.sort(key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tple_lst_imo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Iterate and sort values\n",
    "tple_lst_ga = []\n",
    "for key, val in vocab.iteritems():\n",
    "    log_prob = feature_log_prob_[3, val]\n",
    "    tple = (key, log_prob)\n",
    "    tple_lst_ga.append(tple)\n",
    "tple_lst_ga.sort(key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tple_lst_ga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[(u'20', -4.7810020020779875),\n",
    " (u'the', -4.9325254336238746),\n",
    " (u'and', -5.2304013315184568),\n",
    " (u'to', -5.3091571978161367),\n",
    " (u'enron', -5.364592331533772),\n",
    " (u'of', -5.5016847159071176),\n",
    " (u'will', -5.7089595216371176),\n",
    " (u'in', -5.7598478677892659),\n",
    " (u'for', -6.0143773222161423),\n",
    " (u'you', -6.183595529067909),\n",
    " (u'01', -6.2290358428208341),\n",
    " ...\n",
    "  (u'evans', -9.0862849483760009),\n",
    " (u'html', -9.0881967873435361),\n",
    " (u'meet', -9.0887863896243211),\n",
    " (u'dr', -9.0903560630797937),\n",
    " (u'structure', -9.0907329426289554),\n",
    " (u'primary', -9.0910111100746498),\n",
    " (u'lotus', -9.0923552285607805),\n",
    " (u'persons', -9.0929065714062851),\n",
    " (u'liable', -9.093736651422045),\n",
    " (u'ticket', -9.0939396910810189),\n",
    " (u'phenomenal', -9.094347555285152),\n",
    " ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Iterate and sort values\n",
    "tple_lst_hr = []\n",
    "for key, val in vocab.iteritems():\n",
    "    log_prob = feature_log_prob_[4, val]\n",
    "    tple = (key, log_prob)\n",
    "    tple_lst_hr.append(tple)\n",
    "tple_lst_hr.sort(key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tple_lst_hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Iterate and sort values\n",
    "tple_lst_personal = []\n",
    "for key, val in vocab.iteritems():\n",
    "    log_prob = feature_log_prob_[5, val]\n",
    "    tple = (key, log_prob)\n",
    "    tple_lst_personal.append(tple)\n",
    "tple_lst_personal.sort(key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tple_lst_personal"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
